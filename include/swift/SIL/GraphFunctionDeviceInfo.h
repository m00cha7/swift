//===- GraphFunctionDeviceInfo.h - Utils for setting op devices *- C++ -*-===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2017 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//
//
// This file defines utilities for assigning ops to devices.
//
//===----------------------------------------------------------------------===//

#ifndef SWIFT_SIL_GRAPHFUNCTIONDEVICEINFO_H
#define SWIFT_SIL_GRAPHFUNCTIONDEVICEINFO_H

#include "swift/Basic/LLVM.h"
#include "llvm/ADT/StringRef.h"

namespace swift {
class ASTContext;
class SILFunction;
struct GraphOperationAttribute;

namespace tf {
class GraphOperationBuilder;
struct GraphOperationInfo;

/// The device of a tfop instruction (and its output tensors, if any).
enum class DeviceType {
  INVALID,
  CPU,
  GPU,
  TPU,
  /// Indicates this instruction should run on all devices in
  /// `GraphFunctionDeviceInfo::usedDeviceTypes`. For example, a promoted
  /// scalar will run on all such devices, in case it is a loop iteration count
  /// and the loop runs on all devices.
  ALL,
};

static const char TF_DEFAULT_CPU_DEVICE[] =
    "/job:localhost/replica:0/task:0/device:CPU:0";
static const char TF_DEFAULT_GPU_DEVICE[] =
    "/job:localhost/replica:0/task:0/device:GPU:0";
static const char TF_DEFAULT_TPU_DEVICE[] = "TPU_SYSTEM";
// This is a pseudo-device that only exist in the SIL code generated by
// TFPartition and GraphPartitioner, and will be replaced with real devices in
// TFGraphLowering.
static const char TF_ALL_DEVICES[] = "ALL_DEVICES";

/// Must be kepted in sync with the enum class above.
static const int TF_NUM_DEVICE_TYPES = 5;

static inline DeviceType getOpDeviceType(llvm::StringRef device) {
  if (device.str() == TF_DEFAULT_CPU_DEVICE)
    return DeviceType::CPU;
  if (device.str() == TF_DEFAULT_GPU_DEVICE)
    return DeviceType::GPU;
  if (device.str() == TF_DEFAULT_TPU_DEVICE)
    return DeviceType::TPU;
  if (device.str() == TF_ALL_DEVICES)
    return DeviceType::ALL;

  // FIXME: Consider also supporting variants of the device string, such as
  // "CPU:0".
  llvm_unreachable("Unknown device type");
}

/// The returned string is compatible with TF device name used in TF graphs.
static inline std::string getDeviceString(DeviceType deviceType) {
  switch (deviceType) {
  case DeviceType::CPU:
    return TF_DEFAULT_CPU_DEVICE;
  case DeviceType::GPU:
    return TF_DEFAULT_GPU_DEVICE;
  case DeviceType::TPU:
    return TF_DEFAULT_TPU_DEVICE;
  case DeviceType::ALL:
    return TF_ALL_DEVICES;
  case DeviceType::INVALID:
    llvm_unreachable("Unsupported device type");
  }
}

/// This struct holds information about the deviceInfo of the graph we are
/// generating.
struct GraphFunctionDeviceInfo {
  const DeviceType primaryDeviceType;
  const bool isTPUInfeedEnabled;

  unsigned numUsedDeviceTypes;

  /// This class provides iterator support for a set of device types represented
  /// in a boolean array.
  class DeviceTypeMgr {
    const bool *usedDeviceTypes;

  public:
    /// `usedDeviceTypes` must have exactly TF_NUM_DEVICE_TYPES elements, and
    /// the elements corresponding to DeviceType::INVALID and DeviceType::ALL
    /// must not be set.
    DeviceTypeMgr(const bool *usedDeviceTypes)
        : usedDeviceTypes(usedDeviceTypes) {}

    class iterator
        : public std::iterator<std::input_iterator_tag, // iterator_category
                               DeviceType,              // value_type
                               long,                    // difference_type
                               const DeviceType *,      // pointer
                               DeviceType               // reference
                               > {
      const bool *usedDeviceTypes;
      unsigned deviceIdx;

    public:
      explicit iterator(const bool *usedDeviceTypes, unsigned deviceIdx)
          : usedDeviceTypes(usedDeviceTypes), deviceIdx(deviceIdx) {
        assert(deviceIdx >= 0);
        assert(deviceIdx <= TF_NUM_DEVICE_TYPES);
      }
      iterator &operator++() {
        while (++deviceIdx < TF_NUM_DEVICE_TYPES) {
          if (!usedDeviceTypes[deviceIdx])
            continue;
          auto ret = (DeviceType)deviceIdx;
          assert(ret != DeviceType::INVALID);
          assert(ret != DeviceType::ALL);
          return *this;
        }
        return *this;
      }
      iterator operator++(int) {
        iterator retval = *this;
        ++(*this);
        return retval;
      }
      bool operator==(iterator other) const {
        return usedDeviceTypes == other.usedDeviceTypes &&
               deviceIdx == other.deviceIdx;
      }
      bool operator!=(iterator other) const { return !(*this == other); }
      reference operator*() const { return (DeviceType)deviceIdx; }
    };
    iterator begin() {
      auto ret = iterator(usedDeviceTypes, 0);
      // We know the first entry in `usedDeviceTypes` is not valid, so we use ++
      // to return the first valid entry.
      return ++ret;
    }
    iterator end() { return iterator(usedDeviceTypes, TF_NUM_DEVICE_TYPES); }
  };

  DeviceTypeMgr getUsedDeviceTypes() const {
    return DeviceTypeMgr(usedDeviceTypes);
  }

  /// Return the deviceInfo for the specified function.
  static GraphFunctionDeviceInfo getForFunction(SILFunction &fn,
                                                bool removeConfigInst);

  /// Whether this is an op that configures the function's device.
  static bool isConfigOp(const GraphOperationInfo &opInfo);

  void markDeviceUsed(DeviceType device) {
    assert(device != DeviceType::INVALID);
    if (device == DeviceType::ALL || usedDeviceTypes[(unsigned)device])
      return;
    usedDeviceTypes[(unsigned)device] = true;
    ++numUsedDeviceTypes;
  }

  // Choose a device for the graphOpInst under construction and track the chosen
  // device in `usedDeviceTypes`.
  //
  // If `opDevice` is already set, respects that device choice. Otherwise,
  // chooses a device based on this deviceInfo and op kernel device
  // availability.
  //
  // `attributes` are a list of GraphOperation level attributes which will
  // eventually be passed to TF_OpSetAttr*. These are used here to determine
  // kernel availability on a device.
  //
  // Returns the chosen device.
  std::string
  handleDevicePlacement(llvm::StringRef opType, llvm::StringRef opDevice,
                        llvm::ArrayRef<GraphOperationAttribute> attributes);

  // Same as above, but adds a "__device" attribute to `opBuilder` instead of
  // returning the device.
  //
  // Caller should avoid adding duplicate device attributes (e.g. calling
  // handleDevicePlacement() multiple times when creating the same graph_op
  // inst). Otherwise SILVerifier will fail on that graph_op inst.
  void
  handleDevicePlacement(llvm::StringRef opType, llvm::StringRef opDevice,
                        ASTContext &ctx, GraphOperationBuilder *opBuilder);

private:
  GraphFunctionDeviceInfo(DeviceType primaryDeviceType, bool isTPUInfeedEnabled)
      : primaryDeviceType(primaryDeviceType),
        isTPUInfeedEnabled(isTPUInfeedEnabled) {
    assert(primaryDeviceType != DeviceType::ALL);
    memset(usedDeviceTypes, 0, sizeof(usedDeviceTypes));
    usedDeviceTypes[(unsigned)primaryDeviceType] = true;
    numUsedDeviceTypes = 1;
  }

  // `attributes` are used here to determine kernel availability (primarily
  // dtype constraints).
  DeviceType
  chooseDevice(llvm::StringRef opType,
               llvm::ArrayRef<GraphOperationAttribute> attributes) const;

  // Actual TF devices involved in the tensor computation.
  // It cannot contain DeviceType::ALL.
  bool usedDeviceTypes[TF_NUM_DEVICE_TYPES];
};

} // end namespace tf
} // end namespace swift

#endif
